{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def show_as_image(binary_image):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(binary_image, cmap='gray')\n",
    "    plt.xticks([]); plt.yticks([])\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, utils\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pixel CNN\n",
    "\n",
    "Alternative to Pixel RNN from [Pixel Recurrent Neural Networks](https://arxiv.org/pdf/1601.06759.pdf). \n",
    "\n",
    "On-line resources:\n",
    " * See for an existing PyTorch implementation https://github.com/jzbontar/pixelcnn-pytorch/blob/master/main.py\n",
    " * http://sergeiturukin.com/2017/02/22/pixelcnn.html for a nice walk-through\n",
    " * http://tinyclouds.org/residency/\n",
    " * https://tensorflow.blog/2016/11/29/pixelcnn-1601-06759-summary/ (in korean ;) ) \n",
    "\n",
    "The core ideas are the following:\n",
    "\n",
    "### Joint distribution of an image $\\mathbf{x}$ modelled as an autoregressive process\n",
    "\n",
    "Same model for PixelRNN and PixelCNN:\n",
    "\n",
    "$$p(\\mathbf{x}) = \\prod_{i=1}^{n^2} p(x_i|x_{1}, \\dots, x_{i-1})$$\n",
    " \n",
    "![](http://sergeiturukin.com/assets/2017-02-22-183010_479x494_scrot.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASUAAAElCAYAAACiZ/R3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABDFJREFUeJzt17Ftw0AUBUGeoRLk2CzC/VcgFqHcPZxTOxJpgNBCnolf\n8KPF3ZhzLgAVb88+AOAnUQJSRAlIESUgRZSAFFECUkQJSBElIEWUgBRRAlIuR8bX63Wu63rSKcAr\n27bta875/mh3KErrui632+3vVwH/1hjjvmfn+wakiBKQIkpAiigBKaIEpIgSkCJKQIooASmiBKSI\nEpAiSkCKKAEpogSkiBKQIkpAiigBKaIEpIgSkCJKQIooASmiBKSIEpAiSkCKKAEpogSkiBKQIkpA\niigBKaIEpIgSkCJKQIooASmiBKSIEpAiSkCKKAEpogSkiBKQIkpAiigBKaIEpIgSkCJKQIooASmi\nBKSIEpAiSkCKKAEpogSkiBKQIkpAiigBKaIEpIgSkCJKQIooASmiBKSIEpAiSkCKKAEpogSkiBKQ\nIkpAiigBKaIEpIgSkCJKQIooASmiBKSIEpAiSkCKKAEpogSkiBKQIkpAiigBKaIEpIgSkCJKQIoo\nASmiBKSIEpAiSkCKKAEpogSkiBKQIkpAiigBKaIEpIgSkCJKQIooASmiBKSIEpAiSkCKKAEpogSk\niBKQIkpAiigBKaIEpIgSkCJKQIooASmiBKSIEpByefYBnGuM8ewT4BAvJSBFlIAUUQJSRAlIESUg\nRZSAFFECUkQJSBElIEWUgBRRAlJECUgRJSBFlIAUUQJSRAlIESUgRZSAFFECUkQJSBElIEWUgBRR\nAlJECUgRJSBFlIAUUQJSRAlIESUgRZSAFFECUkQJSBElIEWUgBRRAlJECUgRJSBFlIAUUQJSRAlI\nESUgRZSAFFECUkQJSBElIEWUgBRRAlJECUgRJSBFlIAUUQJSRAlIESUgZcw594/H2D8G+G2bc34+\nGnkpASmiBKSIEpAiSkCKKAEpogSkiBKQIkpAiigBKaIEpIgSkCJKQIooASmiBKSIEpAiSkCKKAEp\nogSkiBKQIkpAiigBKaIEpIgSkCJKQIooASmiBKSIEpAiSkCKKAEpogSkiBKQIkpAiigBKaIEpIgS\nkCJKQIooASmiBKSIEpAiSkCKKAEpogSkiBKQIkpAiigBKaIEpIgSkCJKQIooASmiBKSIEpAiSkCK\nKAEpogSkiBKQIkpAiigBKaIEpIgSkCJKQIooASmiBKSIEpAiSkCKKAEpogSkiBKQIkpAiigBKaIE\npIgSkCJKQIooASmiBKSIEpAiSkCKKAEpogSkiBKQIkpAiigBKaIEpIgSkCJKQIooASmiBKSIEpAi\nSkCKKAEpogSkiBKQIkpAiigBKaIEpIgSkCJKQIooASmiBKSIEpAiSkCKKAEpogSkiBKQIkpAiigB\nKaIEpIgSkCJKQMrl4P5rWZb7GYcAL+9jz2jMOc8+BGA33zcgRZSAFFECUkQJSBElIEWUgBRRAlJE\nCUgRJSDlG/BoHd7iaQCCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118098ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def causal_mask(width, height, include_center=False):\n",
    "    mask = np.ones(shape=(width, height))\n",
    "    mask[height // 2, width // 2 + include_center:] = 0\n",
    "    mask[height // 2 + 1:] = 0\n",
    "    \n",
    "    return mask\n",
    "\n",
    "print(causal_mask(5, 5))\n",
    "show_as_image(causal_mask(5, 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[  1.,   2.,   3.],\n",
       "         [  4.,   0.,   0.],\n",
       "         [  0.,   0.,   0.]],\n",
       "\n",
       "        [[ 10.,  11.,  12.],\n",
       "         [ 13.,   0.,   0.],\n",
       "         [  0.,   0.,   0.]]],\n",
       "\n",
       "\n",
       "       [[[ 19.,  20.,  21.],\n",
       "         [ 22.,   0.,   0.],\n",
       "         [  0.,   0.,   0.]],\n",
       "\n",
       "        [[ 28.,  29.,  30.],\n",
       "         [ 31.,   0.,   0.],\n",
       "         [  0.,   0.,   0.]]]])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_channels, in_channels, width, height = 2, 2, 3, 3\n",
    "\n",
    "conv_weights = 1 + np.arange(out_channels * in_channels * width * height).reshape((out_channels, in_channels, width, height))\n",
    "\n",
    "masked_weights = conv_weights * causal_mask(width, height)\n",
    "\n",
    "masked_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MaskedConv2d(nn.Conv2d):\n",
    "    def __init__(self, mask_type, *args, **kwargs):\n",
    "        super(MaskedConv2d, self).__init__(*args, **kwargs)\n",
    "        assert mask_type in {'A', 'B'}\n",
    "        self.register_buffer('mask', self.weight.data.clone())\n",
    "        _, _, kH, kW = self.weight.size()\n",
    "        self.mask.fill_(1)\n",
    "        self.mask[:, :, kH // 2, kW // 2 + (mask_type == 'B'):] = 0\n",
    "        self.mask[:, :, kH // 2 + 1:] = 0\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.weight.data *= self.mask\n",
    "        return super(MaskedConv2d, self).forward(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully convolutional network preserving spatial resolution\n",
    "\n",
    "Input to output map      |  Output distribution\n",
    ":-------------------------:|:-------------------------:\n",
    "![](https://tensorflowkorea.files.wordpress.com/2016/11/pixel-cnn1.png)  |  ![](http://tinyclouds.org/residency/pixelcnn.png)\n",
    "\n",
    "Quite a counter-intuitive model:\n",
    "\n",
    " * Convolutional layers bottom to top!\n",
    " * Last layer with `kernel_size=1` and outputs $ n_W \\times n_H \\times n_{pixels}$ logits, inferring $p(\\mathbf{x})$ in one forward pass (during training)\n",
    " * Representation of dimension `n_channels` output by each layer anologous to RNN's internal state vector $\\mathbf{h}$\n",
    " * Necessary to stack enough layers (and/or dillatations) to augment the \"receptive field\" so that output pixels can be influenced by the whole image\n",
    " \n",
    "\n",
    "Below is a minimalistic implementation for 0/1 pixels without many of the bells and whistles of the original paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PixelCNN(nn.Module):\n",
    "    n_channels = 4\n",
    "    kernel_size = 7\n",
    "    padding = 3\n",
    "    n_pixels_out = 2 # binary 0/1 pixels\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(PixelCNN, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            MaskedConv2d('A', in_channels=1, out_channels=self.n_channels, kernel_size=self.kernel_size, padding=self.padding, bias=False), nn.BatchNorm2d(self.n_channels), nn.ReLU(True),\n",
    "            MaskedConv2d('B', self.n_channels, self.n_channels, kernel_size=self.kernel_size, padding=self.padding, bias=False), nn.BatchNorm2d(self.n_channels), nn.ReLU(True),\n",
    "            MaskedConv2d('B', self.n_channels, self.n_channels, kernel_size=self.kernel_size, padding=self.padding, bias=False), nn.BatchNorm2d(self.n_channels), nn.ReLU(True),\n",
    "            nn.Conv2d(in_channels=self.n_channels, out_channels=self.n_pixels_out, kernel_size=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        pixel_logits = self.layers(x)\n",
    "        return pixel_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application on a simple generative model of LCD digits\n",
    "\n",
    "From https://gist.github.com/benjaminwilson/b25a321f292f98d74269b83d4ed2b9a8#file-lcd-digits-dataset-nmf-ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALwAAAElCAYAAABeV4iUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAA2pJREFUeJzt3LGRAjEQAMFbijw+/ww+HXxy0IcAV3DAM922jDWmVDIk\nzVprg4rTuweAVxI8KYInRfCkCJ4UwZMieFIET4rgSdkV/Mz8HjUIPOLeNmfP1YKZcQ+Bj7XWmltr\nHGlIETwpgidF8KQInhTBkyJ4UgRPiuBJETwpgidF8KQInhTBkyJ4UgRPiuBJETwpgifl/O4BjuAL\n8OeauflU9N+ww5MieFIET4rgSRE8KYInRfCkCJ4UwZMieFIET4rgSRE8KYInRfCkCJ4UwZMieFIE\nT4rgSfnKR9zf9OiY57LDkyJ4UgRPiuBJETwpgidF8KQInhTBkyJ4UgRPiuBJETwpgidF8KQInhTB\nkyJ4UgRPiuBJETwpgidF8KQInhTBkyJ4UgRPiuBJETwpgidF8KQInhTBkyJ4UgRPiuBJETwpgidF\n8KQInhTBkyJ4UgRPiuBJETwpgidF8KQInhTBkyJ4UgRPiuBJETwpgidF8KQInhTBkyJ4UgRPiuBJ\nETwpgidF8KQInhTBkyJ4UgRPiuBJETwpgidF8KQInhTBkyJ4UgRPiuBJETwpgidF8KQInhTBkyJ4\nUgRPiuBJETwpgidF8KQInhTBkyJ4UgRPiuBJETwpgidF8KQInhTBkyJ4UgRPiuBJETwpgidF8KQI\nnhTBkyJ4UgRPiuBJETwpgidF8KQInhTBkyJ4UgRPiuBJETwpgidF8KQInhTBkyJ4UgRPiuBJETwp\ngidF8KQInhTBkyJ4UgRPiuBJETwpgidF8KQInhTBkyJ4UgRPiuBJETwpgidF8KQInhTBkyJ4UgRP\niuBJETwpgidF8KQInhTBkyJ4UgRPiuBJETwpgidF8KQInhTBkyJ4UgRPiuBJETwpgidF8KQInhTB\nkyJ4UgRPiuBJETwpgidF8KQInhTBkyJ4UgRPiuBJETwpgidF8KQInhTBkyJ4UgRPiuBJETwpgidF\n8KQInhTBkyJ4UgRPiuBJETwpgidF8KQInhTBkyJ4UgRPiuBJETwpgidF8KQInhTBkyJ4UgRPiuBJ\nETwpgidF8KQInhTBkyJ4UgRPiuBJETwpgidF8KQInhTBkyJ4UgRPiuBJETwp553rr9u2XY4YBB70\nc8+iWWsdPQh8DEcaUgRPiuBJETwpgidF8KQInhTBkyJ4Uv4AmrcVqoHJrzkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b980400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CELL_LENGTH = 4\n",
    "IMAGE_WIDTH, IMAGE_HEIGHT = 2 * CELL_LENGTH + 5, CELL_LENGTH + 4\n",
    "\n",
    "def vertical_stroke(rightness, downness):\n",
    "    \"\"\"\n",
    "    Return a 2d numpy array representing an image with a single vertical stroke in it.\n",
    "    `rightness` and `downness` are values from [0, 1] and define the position of the vertical stroke.\n",
    "    \"\"\"\n",
    "    i = (downness * (CELL_LENGTH + 1)) + 2\n",
    "    j = rightness * (CELL_LENGTH + 1) + 1\n",
    "    x = np.zeros(shape=(IMAGE_WIDTH, IMAGE_HEIGHT), dtype=np.float64)\n",
    "    x[i + np.arange(CELL_LENGTH), j] = 1.\n",
    "    return x\n",
    "\n",
    "def horizontal_stroke(downness):\n",
    "    \"\"\"\n",
    "    Analogue to vertical_stroke, but it returns horizontal strokes.\n",
    "    `downness` is here a value in [0, 1, 2].\n",
    "    \"\"\"\n",
    "    i = (downness * (CELL_LENGTH + 1)) + 1\n",
    "    x = np.zeros(shape=(IMAGE_WIDTH, IMAGE_HEIGHT), dtype=np.float64)\n",
    "    x[i, 2 + np.arange(CELL_LENGTH)] = 1.\n",
    "    return x\n",
    "\n",
    "show_as_image(horizontal_stroke(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALwAAAElCAYAAABeV4iUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAA5RJREFUeJzt3cFtg0AQQFEmch/pv4O0k3t62JRgW4bg8N87IzQSXysO\njD1rrQ0qPs4eAP6S4EkRPCmCJ0XwpAieFMGTInhSBE/KU8HPzNdRg8ArHm1znvm0YGZ8h8DbWmvN\nvWu80pAieFIET4rgSRE8KYInRfCkCJ4UwZMieFIET4rgSRE8KYInRfCkCJ4UwZMieFIET8rt7AGO\n4CfA9zVzd1X033DCkyJ4UgRPiuBJETwpgidF8KQInhTBkyJ4UgRPiuBJETwpgidF8KQInhTBkyJ4\nUgRPiuBJOX2J+4iF6ystHbMvJzwpgidF8KQInhTBkyJ4UgRPiuBJETwpgidF8KQInhTBkyJ4UgRP\niuBJETwpgidF8KQInhTBkyJ4UgRPiuBJETwpgidF8KQInhTBkyJ4UgRPiuBJETwpgidF8KQInhTB\nkyJ4UgRPiuBJETwpgidF8KQInhTBkyJ4UgRPiuBJETwpgidF8KQInhTBkyJ4UgRPiuBJETwpgidF\n8KQInhTBkyJ4UgRPiuBJETwpgidF8KQInhTBkyJ4UgRPiuBJETwpgidF8KQInhTBkyJ4UgRPiuBJ\nETwpgifldvYAM7P7Pddau9+z7IhndBYnPCmCJ0XwpAieFMGTInhSBE+K4EkRPCmCJ0XwpAieFMGT\nInhSBE+K4EkRPCmCJ0XwpAielNOXuI9YuL7S0vE7uNIzcsKTInhSBE+K4EkRPCmCJ0XwpAieFMGT\nInhSBE+K4EkRPCmCJ0XwpAieFMGTInhSBE+K4EkRPCmCJ0XwpAieFMGTInhSBE+K4EkRPCmCJ0Xw\npAieFMGTInhSBE+K4EkRPCmCJ0XwpAieFMGTInhSBE+K4EkRPCmCJ0XwpAieFMGTInhSBE+K4EkR\nPCmCJ0XwpAieFMGTInhSBE+K4EkRPCmCJ0XwpAieFMGTInhSBE+K4EkRPCmCJ0XwpAieFMGTInhS\nBE+K4EkRPCmCJ0XwpAieFMGTInhSBE/K7ewBZubsEbjjSs/ICU+K4EkRPCmCJ0XwpAieFMGTInhS\nBE+K4EkRPCmCJ0XwpAieFMGTInhSBE+K4EkRPCmCJ0XwpAieFMGTInhSBE+K4EkRPCmCJ0XwpAie\nFMGTInhSBE+K4EkRPCmCJ0XwpAieFMGTInhSBE/Ks//E/bNt2/cRg8CLPh+5aNZaRw8Cb8MrDSmC\nJ0XwpAieFMGTInhSBE+K4EkRPCm/ZeMhtl31H20AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116b2ce80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BASE_STROKES = np.asarray(\n",
    "    [horizontal_stroke(k) for k in range(3)] + [vertical_stroke(k, l) for k in range(2) for l in range(2)])\n",
    "\n",
    "def random_strokes(strokes=BASE_STROKES, candidate_n_strokes=[2, 3, 4, 5]):\n",
    "    \"\"\"\n",
    "    Return a random composition of 2, 3, 4, or 5 strokes as a single 2d numpy array.\n",
    "    (So not guaranteed to look like a real digit!)\n",
    "    \"\"\"\n",
    "    num_strokes = np.random.choice(candidate_n_strokes)\n",
    "    strokes_indexes = np.random.choice(strokes.shape[0], size=num_strokes, replace=False)\n",
    "    combined_strokes = strokes[strokes_indexes, :, :].sum(axis=0)\n",
    "    return combined_strokes\n",
    "\n",
    "\n",
    "show_as_image(random_strokes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALwAAAElCAYAAABeV4iUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAA51JREFUeJzt3cFNw0AQQNEMSh/03wHtcKeHpQQSxWbB/72zZY3kr5UP\nnmTWWjeoeNs9APwmwZMieFIET4rgSRE8KYInRfCkCJ6Up4KfmY+zBoFXPNrmPPNpwcz4DoE/a601\nP13jlYYUwZMieFIET4rgSRE8KYInRfCkCJ4UwZMieFIET4rgSRE8KYInRfCkCJ4UwZMieFLuuwc4\ng58AP9bMj6ui/4YTnhTBkyJ4UgRPiuBJETwpgidF8KQInhTBkyJ4UgRPiuBJETwpgidF8KQInhTB\nkyJ4UgRPyvYl7jMWrq+0dMyxnPCkCJ4UwZMieFIET4rgSRE8KYInRfCkCJ4UwZMieFIET4rgSRE8\nKYInRfCkCJ4UwZMieFIET4rgSRE8KYInRfCkCJ4UwZMieFIET4rgSRE8KYInRfCkCJ4UwZMieFIE\nT4rgSRE8KYInRfCkCJ4UwZMieFIET4rgSRE8KYInRfCkCJ4UwZMieFIET4rgSRE8KYInRfCkCJ4U\nwZMieFIET4rgSRE8KYInRfCkCJ4UwZMieFIET4rgSRE8KYInRfCkCJ4UwZMieFIET4rgSRE8KYIn\nRfCkCJ6U++4BZubwe661Dr9n2RnPaBcnPCmCJ0XwpAieFMGTInhSBE+K4EkRPCmCJ0XwpAieFMGT\nInhSBE+K4EkRPCmCJ0XwpAielO1L3Ge40tLxX3DGUvyuZ+SEJ0XwpAieFMGTInhSBE+K4EkRPCmC\nJ0XwpAieFMGTInhSBE+K4EkRPCmCJ0XwpAieFMGTInhSBE+K4EkRPCmCJ0XwpAieFMGTInhSBE+K\n4EkRPCmCJ0XwpAieFMGTInhSBE+K4EkRPCmCJ0XwpAieFMGTInhSBE+K4EkRPCmCJ0XwpAieFMGT\nInhSBE+K4EkRPCmCJ0XwpAieFMGTInhSBE+K4EkRPCmCJ0XwpAieFMGTInhSBE+K4EkRPCmCJ0Xw\npAieFMGTInhSBE+K4EkRPCmCJ0XwpAielPvuAc6w1to9wqXMzO4RDuOEJ0XwpAieFMGTInhSBE+K\n4EkRPCmCJ0XwpAieFMGTInhSBE+K4EkRPCmCJ0XwpAieFMGTcskl7istHXMsJzwpgidF8KQInhTB\nkyJ4UgRPiuBJETwpgidF8KQInhTBkyJ4UgRPiuBJETwpgidF8KQInpRnl7i/brfb5xmDwIveH7lo\n/E07JV5pSBE8KYInRfCkCJ4UwZMieFIET4rgSfkG6rQhuNKVaFcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117541048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DIGITS_STROKES = np.array([[0, 2, 3, 4, 5, 6], [5, 6], [0, 1, 2, 4, 5], [0, 1, 2, 5, 6], [1, 3, 5, 6], [0, 1, 2, 3, 6], [0, 1, 2, 3, 5, 6], [0, 5, 6], np.arange(7), [0, 1, 2, 3, 5, 6]])\n",
    "\n",
    "def random_digits(strokes=BASE_STROKES, digit_as_strokes=DIGITS_STROKES):\n",
    "    label = np.random.choice(len(digit_as_strokes))\n",
    "    combined_strokes = strokes[digit_as_strokes[label], :, :].sum(axis=0)\n",
    "    return combined_strokes, label\n",
    "\n",
    "\n",
    "x, label = random_digits()\n",
    "print(label)\n",
    "show_as_image(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       " (0 ,0 ,.,.) = \n",
       "    0   0   0   0   0   0   0   0\n",
       "    0   0   0   0   0   0   0   0\n",
       "    0   1   0   0   0   0   1   0\n",
       "    0   1   0   0   0   0   1   0\n",
       "    0   1   0   0   0   0   1   0\n",
       "    0   1   0   0   0   0   1   0\n",
       "    0   0   1   1   1   1   0   0\n",
       "    0   0   0   0   0   0   1   0\n",
       "    0   0   0   0   0   0   1   0\n",
       "    0   0   0   0   0   0   1   0\n",
       "    0   0   0   0   0   0   1   0\n",
       "    0   0   0   0   0   0   0   0\n",
       "    0   0   0   0   0   0   0   0\n",
       " \n",
       " (1 ,0 ,.,.) = \n",
       "    0   0   0   0   0   0   0   0\n",
       "    0   0   0   0   0   0   0   0\n",
       "    0   0   0   0   0   0   1   0\n",
       "    0   0   0   0   0   0   1   0\n",
       "    0   0   0   0   0   0   1   0\n",
       "    0   0   0   0   0   0   1   0\n",
       "    0   0   0   0   0   0   0   0\n",
       "    0   0   0   0   0   0   1   0\n",
       "    0   0   0   0   0   0   1   0\n",
       "    0   0   0   0   0   0   1   0\n",
       "    0   0   0   0   0   0   1   0\n",
       "    0   0   0   0   0   0   0   0\n",
       "    0   0   0   0   0   0   0   0\n",
       " \n",
       " (2 ,0 ,.,.) = \n",
       "    0   0   0   0   0   0   0   0\n",
       "    0   0   1   1   1   1   0   0\n",
       "    0   1   0   0   0   0   1   0\n",
       "    0   1   0   0   0   0   1   0\n",
       "    0   1   0   0   0   0   1   0\n",
       "    0   1   0   0   0   0   1   0\n",
       "    0   0   1   1   1   1   0   0\n",
       "    0   0   0   0   0   0   1   0\n",
       "    0   0   0   0   0   0   1   0\n",
       "    0   0   0   0   0   0   1   0\n",
       "    0   0   0   0   0   0   1   0\n",
       "    0   0   1   1   1   1   0   0\n",
       "    0   0   0   0   0   0   0   0\n",
       " [torch.FloatTensor of size 3x1x13x8], \n",
       "  4\n",
       "  1\n",
       "  9\n",
       " [torch.LongTensor of size 3x1]]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class LcdDigits(Dataset):\n",
    "\n",
    "    def __init__(self, n_examples):\n",
    "        digits, labels = zip(*[random_digits() for _ in range(n_examples)])\n",
    "        self.digits = np.asarray(digits, dtype=np.float64)\n",
    "        self.labels = np.asarray(labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        digit_with_channel = self.digits[idx][np.newaxis, :, :]\n",
    "        \n",
    "        return torch.from_numpy(digit_with_channel).float(), torch.from_numpy(np.array([self.labels[idx]]))\n",
    "\n",
    "next(b for b in DataLoader(LcdDigits(128), batch_size=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Iter [1/50] Loss: 0.6471\n",
      "Epoch [2/15], Iter [1/50] Loss: 0.1262\n",
      "Epoch [3/15], Iter [1/50] Loss: 0.0329\n",
      "Epoch [4/15], Iter [1/50] Loss: 0.0285\n",
      "Epoch [5/15], Iter [1/50] Loss: 0.0268\n",
      "Epoch [6/15], Iter [1/50] Loss: 0.0271\n",
      "Epoch [7/15], Iter [1/50] Loss: 0.0263\n",
      "Epoch [8/15], Iter [1/50] Loss: 0.0258\n",
      "Epoch [9/15], Iter [1/50] Loss: 0.0252\n",
      "Epoch [10/15], Iter [1/50] Loss: 0.0247\n",
      "Epoch [11/15], Iter [1/50] Loss: 0.0245\n",
      "Epoch [12/15], Iter [1/50] Loss: 0.0243\n",
      "Epoch [13/15], Iter [1/50] Loss: 0.0242\n",
      "Epoch [14/15], Iter [1/50] Loss: 0.0240\n",
      "Epoch [15/15], Iter [1/50] Loss: 0.0238\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "N_EPOCHS = 15\n",
    "BATCH_SIZE = 128\n",
    "LR = 0.01\n",
    "\n",
    "cnn = PixelCNN()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)\n",
    "\n",
    "train_dataset = LcdDigits(BATCH_SIZE * 50)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    for i, (images, _) in enumerate(train_loader):\n",
    "        images = Variable(images)\n",
    "        optimizer.zero_grad()\n",
    "        loss = F.cross_entropy(input=cnn(images), target=torch.squeeze(images).long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f' \n",
    "                   %(epoch+1, N_EPOCHS, i+1, len(train_dataset)//BATCH_SIZE, loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGEAAACdCAIAAAArNIGWAAAC9ElEQVR4nO2aQXLjMAwElf3/n5XL\n1sb2WhqOCAig031KEBakmhKHAJhtA5jn699P+77/RL/q40eU5Xn8w+OvL/GR543kubzejYfk//M2\nFzyCRho00vT1yKj8Ue9je54bj8of5dlWnL2mQSMNGml+QX1sEpUH4Jn76pqqeirrPWVPG9VDuuuz\n67i3cc41DRpp0EhT750uXXrj23pUN/+k9x9xvp69pkEjDRpp6ueH2c/NnmcCjFH/ra7SA9v3tNkz\nfDdPVH7uaS+CRho00iTO8QaLi251Tfo9bVKeI/DsLuRq9Bm1fK5Gg1umOYl19uRH1K1ez+IzviPQ\n1N9/dpsTlc38k2b498Spj554++GgkQaNNH3/b6yblx+ui5pDZs8b3bj1Puw1DRpp0EjTt1fsdqcE\nMEd9z7lK/JXbekj3uUfrU9+fc02DRho00tTXF928Od2zJ/McJXTXu3nw7FnQSINGms/x1Kq5JcAY\n9d9qtz0VVh8drXfjSfWR+/7neTjXtm3b9n0/kQ+N/nKyrdBIc9+s3l3f7Qw5W2fFpSleyxN+VgyC\nZ/+AZw+BZ08R37N182yAHtT3iqvE7R7yhfA7guw4M/9g0EiDRpoGXmjSzrNP3q8kntTE4tmzoJEG\njTT1HuyyytkC8Mzn1zVhM3+3F43qXauea8U51zRopEEjTb13LlO/fOT8MOq57DUNGmnQSNOgfjVp\n5+UAQ9T/z3B2/qy9eVv9kt0Du3nerudc06CRBo00680Vo0j37EFTj/LU7Px49ixopEEjzXqe3a3H\nBhij7xyn+569XL+4eaLiqb0x55oGjTRopMGzr75n+X3sUdw9KybX49mjoJEGjTS/17Pd5wLMUd8r\nVu1Ze707Yz9f9n+86p425Lmcaxo00qCRZr370i5nxWVPzc5TEmevadBIg0aa+np3Vc8G8Oj7rbbr\npSd7S5kntee88D6DeaiPRkEjDRpp6ud7q9RN7XrXVj0we02DRho00tznkS7Z96v0rpF8Aw6kVH1x\nLcINAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 219,
     "metadata": {
      "image/png": {
       "height": 500,
       "width": 500
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_samples(n_samples, starting_point=(0, 0), starting_image=None):\n",
    "\n",
    "    samples = torch.from_numpy(\n",
    "        starting_image if starting_image is not None else np.zeros((n_samples * n_samples, 1, IMAGE_WIDTH, IMAGE_HEIGHT))).float()\n",
    "\n",
    "    cnn.train(False)\n",
    "\n",
    "    for i in range(IMAGE_WIDTH):\n",
    "        for j in range(IMAGE_HEIGHT):\n",
    "            if i < starting_point[0] or (i == starting_point[0] and j < starting_point[1]):\n",
    "                continue\n",
    "            out = cnn(Variable(samples, volatile=True))\n",
    "            probs = F.softmax(out[:, :, i, j]).data\n",
    "            samples[:, :, i, j] = torch.multinomial(probs, 1).float()\n",
    "    return samples\n",
    "\n",
    "n_samples = 12\n",
    "samples = generate_samples(n_samples)\n",
    "\n",
    "utils.save_image(samples, 'sample_{:02d}.png'.format(1), nrow=n_samples, padding=0)\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(filename='sample_{:02d}.png'.format(1), width=500, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGEAAACdCAIAAAArNIGWAAAC1UlEQVR4nO2a0XICIQxFa///n7cP\nnamtXfYSCdyg5zy1EbPxjoQk+PEBMM7t56/jOO7Wm7a3iPpx2aPx/3nh978te8tv1I902Ln++u2D\ncX72PPLNQSMNGmleJ2dHCft35eyLuOvY2WsaNNKgkeZ9czbAWvLri+j6Xey2+mWwB87y34L6qBc0\n0qCRxl93uOaKo/7tOdu1/tTOXtOgkQaNNP6eMO1uJ7ienhnWsm6WHl1fbg5Vbeaf1WOn9Mycaxo0\n0qCRpm4PObtO2WYO2bJ3xtOCnvZOVLvn2FujNaCRpm6O7InnOA4ZKj0q1MDfQ1ab+ffiui997h51\n3D897ShopEEjTf6MPctP9TPBnrNbfix29poGjTRopFlXp1bPwQBz8X/nd7Hb7lejvWv0uSmfi3NN\ng0YaNNL46xFXnTUaT9mes/ONufNP9poGjTRopPH3irv0xgBj+OugKvWOXD+7Dhqsa6Lr6WlXg0Ya\nNNK878x/1hyytb7F7Ny/Zi7KXtOgkQaNNPvVu9XmlgB9+OuOXeyPLKtT6GlfBDTSoJEmf1a/e6/b\ni/0edfC55OzVoJEGjTTrcvYud1MAc1j33atWB6XN/B/YZVb/dL12uoxzTYNGGjTSkLN77VefJ8Ue\nzamdfloB5MbDXtOgkQaNNOTsXjvAGP45TtRP1nPTZv5TZ+n9floO0+M8tXOuadBIg0aaurm5nP/Z\nveK123H71DjZaxo00qCR5vV/Yzz7uQB9+Ocy1eqgtHvaIveua+opzjUNGmnQSOOvO6rZm1TL2VF7\n9I0h/+w1DRpp0Ejjz5FZPST3sVAb/96ptsd749+l3pnd637DuaZBIw0aafwz/6gf1xlyte7Uvul9\nbAt62lHQSINGGn+d3aJ6zgaI4e8Vd7E/smaW/n+B/U7h1A/nmgaNNGik2W9OGI0zuj6tp43ao3PF\nUvGw1zRopEEjjf+3wa57VO5vM/kCkhBsd0OTPkoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 220,
     "metadata": {
      "image/png": {
       "height": 500,
       "width": 500
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starting_images = np.expand_dims(np.stack([random_digits()[0] for _ in range(n_samples*n_samples)]), axis=1)\n",
    "\n",
    "samples = generate_samples(n_samples=12, starting_point=(3, 5), starting_image=starting_images)\n",
    "\n",
    "utils.save_image(samples, 'sample_{:02d}.png'.format(1), nrow=n_samples, padding=0)\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(filename='sample_{:02d}.png'.format(1), width=500, height=500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
